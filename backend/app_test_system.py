#!/usr/bin/env python3
"""
Test Tabanlƒ± V√ºcut Analizi Sistemi - Tamamen D√ºzeltilmi≈ü Versiyon
- T√ºm WebSocket timeout sorunlarƒ± √ß√∂z√ºld√º
- RealSense kamera kararlƒ±lƒ±ƒüƒ± iyile≈ütirildi
- Heartbeat sistemi optimize edildi
- Hata y√∂netimi geli≈ütirildi
"""

import eventlet
eventlet.monkey_patch()

from flask import Flask, request
from flask_socketio import SocketIO, emit
from flask_cors import CORS
import cv2
import numpy as np
import base64
import time
import logging
import json
import requests
import io
from PIL import Image
from typing import Optional, Tuple, Dict, Any
import threading
import random
# --- Food Analysis ---
from food_analyzer import FoodAnalyzer

# --- Food Analysis ---
from food_analyzer import FoodAnalyzer

def capture_realsense_photo():
    """RealSense ile fotoƒüraf √ßek"""
    global realsense_pipeline
    
    try:
        # RealSense pipeline ba≈ülat
        realsense_pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        
        profile = realsense_pipeline.start(config)
        
        # Birka√ß frame bekle (kamera stabilize olsun)
        for _ in range(10):
            realsense_pipeline.wait_for_frames()
        
        # Fotoƒüraf √ßek
        frames = realsense_pipeline.wait_for_frames()
        color_frame = frames.get_color_frame()
        
        if color_frame:
            color_image = np.asanyarray(color_frame.get_data())
            color_image = cv2.flip(color_image, 1)  # Mirror
            
            # JPEG formatƒ±na √ßevir
            _, buffer = cv2.imencode('.jpg', color_image, [cv2.IMWRITE_JPEG_QUALITY, 95])
            return buffer.tobytes()
        
        return None
        
    except Exception as e:
        print(f"RealSense fotoƒüraf hatasƒ±: {e}")
        return None
    finally:
        if realsense_pipeline:
            realsense_pipeline.stop()

def capture_webcam_photo():
    """Webcam ile fotoƒüraf √ßek"""
    global camera
    
    try:
        # Webcam a√ß
        working_cameras = [0, 1, 2, 4, 6]
        working_camera_index = None
        
        for camera_index in working_cameras:
            test_cap = cv2.VideoCapture(camera_index)
            if test_cap.isOpened():
                ret, frame = test_cap.read()
                if ret and frame is not None:
                    working_camera_index = camera_index
                    test_cap.release()
                    break
                test_cap.release()
        
        if working_camera_index is None:
            return None
        
        camera = cv2.VideoCapture(working_camera_index)
        camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        # Birka√ß frame bekle
        for _ in range(10):
            camera.read()
        
        # Fotoƒüraf √ßek
        ret, frame = camera.read()
        
        if ret and frame is not None:
            frame = cv2.flip(frame, 1)  # Mirror
            
            # JPEG formatƒ±na √ßevir
            _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
            return buffer.tobytes()
        
        return None
        
    except Exception as e:
        print(f"Webcam fotoƒüraf hatasƒ±: {e}")
        return None
    finally:
        if camera:
            camera.release()
# --- AI Libraries ---
import tensorflow as tf
import tensorflow_hub as hub
import requests
import io
from PIL import Image

# --- RealSense Library (Optional) ---
try:
    import pyrealsense2 as rs
    REALSENSE_AVAILABLE = True
    print("‚úÖ RealSense k√ºt√ºphanesi bulundu")
except ImportError:
    rs = None
    REALSENSE_AVAILABLE = False
    print("‚ö†Ô∏è RealSense k√ºt√ºphanesi bulunamadƒ± - Webcam modu kullanƒ±lacak")

# --- Flask and SocketIO Setup ---
log = logging.getLogger('werkzeug')
log.setLevel(logging.ERROR)
app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

# WebSocket ayarlarƒ± - tamamen optimize edildi
socketio = SocketIO(app, 
                   cors_allowed_origins="*", 
                   async_mode='eventlet',
                   ping_timeout=60,  # 1 dakika timeout
                   ping_interval=25,  # 25 saniyede bir ping
                   logger=False, 
                   engineio_logger=False,
                   transports=['websocket'],  # Sadece websocket
                   allow_upgrades=False)  # Upgrade'leri devre dƒ±≈üƒ± bƒ±rak

# --- Global Variables ---
test_running = False
test_thread = None
camera = None
realsense_pipeline = None
camera_mode = "webcam"
connected_clients = set()
heartbeat_active = False

# Test parametreleri
TEST_DURATION = 10  # 10 saniye test s√ºresi
ANALYSIS_INTERVAL = 0.5  # Yarƒ±m saniyede bir analiz
FOOD_PHOTO_COUNTDOWN = 3  # Yemek fotoƒürafƒ± i√ßin geri sayƒ±m
FOOD_CAPTURE_COUNTDOWN = 3  # 3 saniye geri sayƒ±m

# API Konfig√ºrasyonu
CLARIFAI_API_KEY = "YOUR_CLARIFAI_API_KEY_HERE"  # Buraya API key'inizi yazƒ±n
CLARIFAI_MODEL_ID = "food-item-recognition"
CLARIFAI_USER_ID = "clarifai"
CLARIFAI_APP_ID = "main"

# Yemek kalori veritabanƒ± (yakla≈üƒ±k deƒüerler)
FOOD_CALORIES_DB = {
    'pizza': 266,
    'burger': 354,
    'sandwich': 250,
    'salad': 150,
    'pasta': 220,
    'rice': 130,
    'chicken': 165,
    'fish': 206,
    'bread': 265,
    'apple': 52,
    'banana': 89,
    'orange': 47,
    'tomato': 18,
    'potato': 77,
    'egg': 155,
    'cheese': 113,
    'milk': 42,
    'coffee': 2,
    'tea': 1,
    'water': 0,
    'soup': 85,
    'cake': 257,
    'cookie': 502,
    'chocolate': 546,
    'ice cream': 207,
    'yogurt': 59,
    'meat': 250,
    'vegetable': 25,
    'fruit': 60,
    'nuts': 607,
    'beans': 347,
    'corn': 86,
    'carrot': 41,
    'broccoli': 34,
    'spinach': 23,
    'lettuce': 15,
    'cucumber': 16,
    'onion': 40,
    'garlic': 149,
    'ginger': 80,
    'lemon': 29,
    'lime': 30,
    'avocado': 160,
    'strawberry': 32,
    'grape': 62,
    'watermelon': 30,
    'pineapple': 50,
    'mango': 60,
    'kiwi': 61,
    'peach': 39,
    'pear': 57,
    'plum': 46
}

# Analiz verileri toplama
analysis_results = []

# Yemek analizi i√ßin global deƒüi≈ükenler
food_capture_active = False
food_capture_thread = None

current_analysis = {
    'omuz_genisligi': 0.0,
    'bel_genisligi': 0.0,
    'omuz_bel_orani': 0.0,
    'vucut_tipi': 'Analiz Bekleniyor',
    'mesafe': 0.0,
    'confidence': 0.0
}

final_analysis = {
    'omuz_genisligi': 0.0,
    'bel_genisligi': 0.0,
    'omuz_bel_orani': 0.0,
    'vucut_tipi': 'Analiz Bekleniyor',
    'mesafe': 0.0,
    'confidence': 0.0,
    'diyet_onerileri': []
}

# Food analyzer
food_analyzer = None

# Kalori hesaplama state'leri
FOOD_PHOTO_COUNTDOWN = 3  # Yemek fotoƒürafƒ± i√ßin geri sayƒ±m

def initialize_food_analyzer():
    """Food analyzer'ƒ± ba≈ülat"""
    global food_analyzer
    try:
        api_key = "920c5f81c0264c2ca92a1d916e604a7694c560e9"
        food_analyzer = FoodAnalyzer(api_key)
        print("‚úÖ Food analyzer ba≈ülatƒ±ldƒ±")
        return True
    except Exception as e:
        print(f"‚ùå Food analyzer ba≈ülatƒ±lamadƒ±: {e}")
        return False
# Food analyzer
food_analyzer = None
food_capture_active = False
food_capture_thread = None

def initialize_food_analyzer():
    """Food analyzer'ƒ± ba≈ülat"""
    global food_analyzer
    try:
        api_key = "29b4f47bf7184373bbe0c8eb1d102529"
        food_analyzer = FoodAnalyzer(api_key)
        print("‚úÖ Food analyzer ba≈ülatƒ±ldƒ±")
        return True
    except Exception as e:
        print(f"‚ùå Food analyzer ba≈ülatƒ±lamadƒ±: {e}")
        return False

# --- Yemek Analiz API Ayarlarƒ± ---
FOOD_API_URL = "https://api.logmeal.es/v2"
FOOD_API_TOKEN = "YOUR_API_TOKEN_HERE"  # Buraya ger√ßek API token'ƒ±nƒ±zƒ± koyun

# Basit yemek veritabanƒ± (API olmadƒ±ƒüƒ±nda kullanƒ±lacak)
SIMPLE_FOOD_DATABASE = {
    'ekmek': {'calories_per_100g': 265, 'typical_portion': 50},
    'tavuk': {'calories_per_100g': 165, 'typical_portion': 150},
    'pirin√ß': {'calories_per_100g': 130, 'typical_portion': 100},
    'salata': {'calories_per_100g': 15, 'typical_portion': 100},
    'meyve': {'calories_per_100g': 50, 'typical_portion': 150},
    'sebze': {'calories_per_100g': 25, 'typical_portion': 100},
    'et': {'calories_per_100g': 250, 'typical_portion': 120},
    'balƒ±k': {'calories_per_100g': 200, 'typical_portion': 150},
    'makarna': {'calories_per_100g': 350, 'typical_portion': 100},
    '√ßorba': {'calories_per_100g': 50, 'typical_portion': 250}
}

# Kalori hesaplama state'leri
calorie_calculation_active = False

# --- Model Loading ---
print("ü§ñ Loading MoveNet model from TensorFlow Hub...")
model = None
movenet = None

def load_movenet_model():
    """Load MoveNet model with retry mechanism"""
    global model, movenet
    
    max_retries = 3
    retry_delay = 5
    
    for attempt in range(max_retries):
        try:
            print(f"üì• Model y√ºkleme denemesi {attempt + 1}/{max_retries}...")
            
            # Timeout ile model y√ºkleme
            import socket
            socket.setdefaulttimeout(60)  # 60 saniye timeout
            
            model = hub.load("https://tfhub.dev/google/movenet/singlepose/lightning/4")
            movenet = model.signatures['serving_default']
            print("‚úÖ MoveNet model loaded successfully.")
            return True
            
        except Exception as e:
            print(f"‚ùå Deneme {attempt + 1} ba≈üarƒ±sƒ±z: {e}")
            if attempt < max_retries - 1:
                print(f"‚è≥ {retry_delay} saniye bekleyip tekrar denenecek...")
                time.sleep(retry_delay)
            else:
                print("‚ùå Model y√ºklenemedi. L√ºtfen internet baƒülantƒ±nƒ±zƒ± kontrol edin.")
                return False
    
    return False

def analyze_food_with_clarifai(image_data):
    """Clarifai API ile yemek analizi yap"""
    try:
        # API key kontrol√º
        if CLARIFAI_API_KEY == "YOUR_CLARIFAI_API_KEY_HERE":
            print("‚ö†Ô∏è Clarifai API key ayarlanmamƒ±≈ü, demo modu kullanƒ±lƒ±yor")
            return analyze_food_demo(image_data)
        
        # Base64 image'i hazƒ±rla
        import base64
        if isinstance(image_data, str):
            # Zaten base64 ise
            image_base64 = image_data
        else:
            # Numpy array'den base64'e √ßevir
            _, buffer = cv2.imencode('.jpg', image_data)
            image_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # Clarifai API isteƒüi
        headers = {
            'Authorization': f'Key {CLARIFAI_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        data = {
            "user_app_id": {
                "user_id": CLARIFAI_USER_ID,
                "app_id": CLARIFAI_APP_ID
            },
            "model_id": CLARIFAI_MODEL_ID,
            "inputs": [
                {
                    "data": {
                        "image": {
                            "base64": image_base64
                        }
                    }
                }
            ]
        }
        
        response = requests.post(
            'https://api.clarifai.com/v2/models/predictions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            
            # Sonu√ßlarƒ± i≈üle
            detected_foods = []
            total_calories = 0
            
            if 'outputs' in result and len(result['outputs']) > 0:
                concepts = result['outputs'][0]['data']['concepts']
                
                for concept in concepts[:5]:  # ƒ∞lk 5 sonu√ß
                    food_name = concept['name'].lower()
                    confidence = concept['value']
                    
                    if confidence > 0.5:  # %50'den y√ºksek g√ºven
                        # Kalori hesapla
                        calories = FOOD_CALORIES_DB.get(food_name, 100)  # Default 100 kalori
                        portion_calories = int(calories * confidence)  # G√ºvene g√∂re ayarla
                        
                        detected_foods.append({
                            'name': food_name.title(),
                            'confidence': confidence,
                            'calories': portion_calories
                        })
                        
                        total_calories += portion_calories
            
            if not detected_foods:
                # Hi√ß yemek bulunamadƒ±ysa
                detected_foods = [{'name': 'Bilinmeyen Yemek', 'confidence': 0.5, 'calories': 150}]
                total_calories = 150
            
            return {
                'detected_foods': detected_foods,
                'total_calories': total_calories,
                'confidence': max([f['confidence'] for f in detected_foods]) if detected_foods else 0.5,
                'api_used': 'Clarifai'
            }
        
        else:
            print(f"‚ùå Clarifai API hatasƒ±: {response.status_code}")
            return analyze_food_demo(image_data)
            
    except Exception as e:
        print(f"‚ùå Clarifai API baƒülantƒ± hatasƒ±: {e}")
        return analyze_food_demo(image_data)

def analyze_food_demo(image_data):
    """Demo yemek analizi (API olmadƒ±ƒüƒ±nda)"""
    import random
    
    demo_foods = [
        {'name': 'Pizza', 'calories': 266},
        {'name': 'Salata', 'calories': 150},
        {'name': 'Tavuk', 'calories': 165},
        {'name': 'Pilav', 'calories': 130},
        {'name': 'Makarna', 'calories': 220},
        {'name': 'Hamburger', 'calories': 354},
        {'name': 'Sandvi√ß', 'calories': 250}
    ]
    
    # Rastgele 1-3 yemek se√ß
    num_foods = random.randint(1, 3)
    selected_foods = random.sample(demo_foods, num_foods)
    
    detected_foods = []
    total_calories = 0
    
    for food in selected_foods:
        confidence = random.uniform(0.6, 0.9)
        calories = int(food['calories'] * random.uniform(0.8, 1.2))  # ¬±20% varyasyon
        
        detected_foods.append({
            'name': food['name'],
            'confidence': confidence,
            'calories': calories
        })
        
        total_calories += calories
    
    return {
        'detected_foods': detected_foods,
        'total_calories': total_calories,
        'confidence': random.uniform(0.7, 0.9),
        'api_used': 'Demo'
    }

def analyze_food_image(image):
    """Yemek g√∂r√ºnt√ºs√ºn√º analiz et ve kalori hesapla"""
    try:
        # Ger√ßek yemek analizi API'si
        print("üîç Yemek analizi ba≈ülƒ±yor...")
        
        # G√∂r√ºnt√ºy√º base64'e √ßevir
        _, buffer = cv2.imencode('.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 85])
        img_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # Clarifai Food Model API'si kullan
        analysis_result = analyze_with_clarifai(img_base64)
        
        if analysis_result:
            return analysis_result
        
        # Fallback: Basit renk analizi
        return analyze_with_color_detection(image)
        
    except Exception as e:
        print(f"‚ùå Yemek analizi hatasƒ±: {e}")
        return analyze_with_color_detection(image)

def analyze_with_clarifai(img_base64):
    """Clarifai API ile yemek analizi"""
    try:
        import requests
        
        # Clarifai API ayarlarƒ±
        API_KEY = "YOUR_CLARIFAI_API_KEY"  # Ger√ßek API key gerekli
        MODEL_ID = "food-item-recognition"
        
        headers = {
            'Authorization': f'Key {API_KEY}',
            'Content-Type': 'application/json'
        }
        
        data = {
            "inputs": [
                {
                    "data": {
                        "image": {
                            "base64": img_base64
                        }
                    }
                }
            ]
        }
        
        url = f"https://api.clarifai.com/v2/models/{MODEL_ID}/outputs"
        
        print("üåê Clarifai API'sine istek g√∂nderiliyor...")
        response = requests.post(url, headers=headers, json=data, timeout=10)
        
        if response.status_code == 200:
            result = response.json()
            return process_clarifai_response(result)
        else:
            print(f"‚ùå Clarifai API hatasƒ±: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"‚ùå Clarifai API baƒülantƒ± hatasƒ±: {e}")
        return None

def process_clarifai_response(api_response):
    """Clarifai API yanƒ±tƒ±nƒ± i≈üle"""
    try:
        detected_foods = []
        total_calories = 0
        
        if 'outputs' in api_response and len(api_response['outputs']) > 0:
            concepts = api_response['outputs'][0]['data']['concepts']
            
            for concept in concepts[:5]:  # ƒ∞lk 5 sonu√ß
                food_name = concept['name']
                confidence = concept['value']
                
                if confidence > 0.5:  # %50'den y√ºksek g√ºven
                    # Basit kalori tahmini (ger√ßek uygulamada nutrition API kullanƒ±lmalƒ±)
                    estimated_calories = estimate_calories_by_food_name(food_name)
                    
                    detected_foods.append({
                        'name': food_name,
                        'confidence': confidence,
                        'calories': estimated_calories
                    })
                    
                    total_calories += estimated_calories
        
        return {
            'detected_foods': detected_foods,
            'total_calories': total_calories,
            'confidence': sum(f['confidence'] for f in detected_foods) / len(detected_foods) if detected_foods else 0,
            'method': 'Clarifai API'
        }
        
    except Exception as e:
        print(f"‚ùå Clarifai yanƒ±t i≈üleme hatasƒ±: {e}")
        return None

def analyze_with_color_detection(image):
    """Renk analizi ile basit yemek tahmini"""
    try:
        print("üé® Renk analizi ile yemek tahmini yapƒ±lƒ±yor...")
        
        # G√∂r√ºnt√ºy√º HSV'ye √ßevir
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # Renk aralƒ±klarƒ± tanƒ±mla
        color_foods = {
            'kƒ±rmƒ±zƒ±_yemek': {
                'range': [(0, 50, 50), (10, 255, 255)],
                'foods': ['domates', 'kƒ±rmƒ±zƒ± et', 'kƒ±rmƒ±zƒ± biber'],
                'avg_calories': 150
            },
            'ye≈üil_yemek': {
                'range': [(40, 50, 50), (80, 255, 255)],
                'foods': ['salata', 'brokoli', 'ye≈üil sebze'],
                'avg_calories': 50
            },
            'sarƒ±_yemek': {
                'range': [(20, 50, 50), (40, 255, 255)],
                'foods': ['muz', 'patates', 'makarna'],
                'avg_calories': 200
            },
            'kahverengi_yemek': {
                'range': [(10, 50, 20), (20, 255, 200)],
                'foods': ['ekmek', 'et', '√ßikolata'],
                'avg_calories': 250
            }
        }
        
        detected_foods = []
        total_calories = 0
        
        for color_name, color_info in color_foods.items():
            lower = np.array(color_info['range'][0])
            upper = np.array(color_info['range'][1])
            
            mask = cv2.inRange(hsv, lower, upper)
            pixel_count = cv2.countNonZero(mask)
            
            if pixel_count > 1000:  # Yeterli pixel varsa
                confidence = min(pixel_count / 10000, 1.0)
                food_name = color_info['foods'][0]  # ƒ∞lk yemek adƒ±nƒ± al
                calories = int(color_info['avg_calories'] * confidence)
                
                detected_foods.append({
                    'name': food_name,
                    'confidence': confidence,
                    'calories': calories
                })
                
                total_calories += calories
        
        if not detected_foods:
            # Hi√ßbir ≈üey bulunamazsa varsayƒ±lan
            detected_foods = [{'name': 'genel yemek', 'confidence': 0.5, 'calories': 200}]
            total_calories = 200
        
        return {
            'detected_foods': detected_foods,
            'total_calories': total_calories,
            'confidence': sum(f['confidence'] for f in detected_foods) / len(detected_foods),
            'method': 'Renk Analizi'
        }
        
    except Exception as e:
        print(f"‚ùå Renk analizi hatasƒ±: {e}")
        return {
            'detected_foods': [{'name': 'bilinmeyen', 'confidence': 0.3, 'calories': 150}],
            'total_calories': 150,
            'confidence': 0.3,
            'method': 'Varsayƒ±lan'
        }

def estimate_calories_by_food_name(food_name):
    """Yemek adƒ±na g√∂re kalori tahmini"""
    calorie_db = {
        'apple': 80, 'banana': 105, 'orange': 60,
        'bread': 250, 'rice': 200, 'pasta': 220,
        'chicken': 165, 'beef': 250, 'fish': 140,
        'salad': 50, 'pizza': 285, 'burger': 540,
        'cake': 350, 'cookie': 150, 'chocolate': 210,
        'milk': 150, 'coffee': 5, 'tea': 2,
        'potato': 160, 'tomato': 18, 'carrot': 25,
        'cheese': 113, 'egg': 70, 'yogurt': 100
    }
    
    # T√ºrk√ße yemek isimleri
    turkish_foods = {
        'elma': 80, 'muz': 105, 'portakal': 60,
        'ekmek': 250, 'pirin√ß': 200, 'makarna': 220,
        'tavuk': 165, 'et': 250, 'balƒ±k': 140,
        'salata': 50, 'pizza': 285, 'hamburger': 540,
        'pasta': 350, 'kurabiye': 150, '√ßikolata': 210,
        's√ºt': 150, 'kahve': 5, '√ßay': 2,
        'patates': 160, 'domates': 18, 'havu√ß': 25,
        'peynir': 113, 'yumurta': 70, 'yoƒüurt': 100
    }
    
    food_lower = food_name.lower()
    
    # √ñnce T√ºrk√ße s√∂zl√ºkte ara
    for turkish_name, calories in turkish_foods.items():
        if turkish_name in food_lower:
            return calories
    
    # Sonra ƒ∞ngilizce s√∂zl√ºkte ara
    for english_name, calories in calorie_db.items():
        if english_name in food_lower:
            return calories
    
    # Bulunamazsa ortalama deƒüer d√∂nd√ºr
    return 150

def simulate_food_detection(image_data):
    """Yemek tespiti sim√ºlasyonu - ger√ßek API ile deƒüi≈ütirilecek"""
    foods_database = [
        {"name": "Elma", "calories": 95},
        {"name": "Muz", "calories": 105},
        {"name": "Tavuk G√∂ƒüs√º (100g)", "calories": 165},
        {"name": "Brokoli (100g)", "calories": 55},
        {"name": "Pirin√ß Pilavƒ± (1 porsiyon)", "calories": 205},
        {"name": "Yumurta (1 adet)", "calories": 70},
        {"name": "Ekmek (1 dilim)", "calories": 80},
        {"name": "Salata (1 porsiyon)", "calories": 35},
        {"name": "Makarna (1 porsiyon)", "calories": 220},
        {"name": "Balƒ±k (100g)", "calories": 140},
        {"name": "Peynir (50g)", "calories": 180},
        {"name": "Domates (1 adet)", "calories": 25},
        {"name": "Patates (1 orta boy)", "calories": 160},
        {"name": "Yogurt (1 kase)", "calories": 120},
        {"name": "√áikolata (50g)", "calories": 250}
    ]
    
    # Rastgele 1-3 yemek se√ß
    num_foods = random.randint(1, 3)
    detected_foods = random.sample(foods_database, num_foods)
    
    total_calories = sum(food["calories"] for food in detected_foods)
    confidence = random.uniform(0.7, 0.95)  # %70-95 g√ºven aralƒ±ƒüƒ±
    
    return {
        "detected_foods": detected_foods,
        "total_calories": total_calories,
        "confidence": confidence,
        "analysis_method": "simulated"
    }

def capture_single_frame():
    """Tek bir frame yakala (kalori hesaplama i√ßin)"""
    global camera_mode
    
    try:
        if camera_mode == "realsense" and REALSENSE_AVAILABLE:
            return capture_realsense_frame()
        else:
            return capture_webcam_frame()
    except Exception as e:
        print(f"‚ùå Frame yakalama hatasƒ±: {e}")
        return None

def capture_realsense_frame():
    """RealSense'den tek frame yakala"""
    pipeline = None
    try:
        pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        
        profile = pipeline.start(config)
        
        # Birka√ß frame bekle (kamera stabilize olsun)
        for _ in range(5):
            frames = pipeline.wait_for_frames(timeout_ms=1000)
        
        # Son frame'i al
        frames = pipeline.wait_for_frames(timeout_ms=1000)
        color_frame = frames.get_color_frame()
        
        if color_frame:
            # RGB g√∂r√ºnt√ºy√º numpy array'e √ßevir ve aynala
            color_image = np.asanyarray(color_frame.get_data())
            color_image = cv2.flip(color_image, 1)  # Mirror
            return color_image
        
        return None
        
    except Exception as e:
        print(f"‚ùå RealSense frame yakalama hatasƒ±: {e}")
        return None
    finally:
        if pipeline:
            pipeline.stop()

def capture_webcam_frame():
    """Webcam'den tek frame yakala"""
    cap = None
    try:
        # √áalƒ±≈üan kamera index'ini bul
        working_cameras = [4, 6, 2, 0, 1]
        working_camera_index = None
        
        for camera_index in working_cameras:
            test_cap = cv2.VideoCapture(camera_index)
            if test_cap.isOpened():
                ret, frame = test_cap.read()
                if ret and frame is not None:
                    working_camera_index = camera_index
                    test_cap.release()
                    break
                test_cap.release()
        
        if working_camera_index is None:
            return None
        
        cap = cv2.VideoCapture(working_camera_index)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        # Birka√ß frame bekle (kamera stabilize olsun)
        for _ in range(5):
            ret, frame = cap.read()
        
        # Son frame'i al
        ret, frame = cap.read()
        if ret and frame is not None:
            frame = cv2.flip(frame, 1)  # Mirror
            return frame
        
        return None
        
    except Exception as e:
        print(f"‚ùå Webcam frame yakalama hatasƒ±: {e}")
        return None
    finally:
        if cap:
            cap.release()

def take_food_photo():
    """Yemek fotoƒürafƒ± √ßek ve analiz et"""
    global camera, realsense_pipeline, camera_mode
    
    try:
        # Kamera t√ºr√ºn√º tespit et
        if not detect_camera_type():
            socketio.emit('food_analysis_error', {'message': 'Kamera bulunamadƒ±'})
            return
        
        if camera_mode == "realsense":
            # RealSense ile fotoƒüraf √ßek
            try:
                realsense_pipeline = rs.pipeline()
                config = rs.config()
                config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
                
                profile = realsense_pipeline.start(config)
                
                # 3 saniye geri sayƒ±m
                for i in range(3, 0, -1):
                    socketio.emit('food_capture_countdown', {'count': i})
                    socketio.sleep(1)
                
                socketio.emit('food_capture_started')
                
                # Fotoƒüraf √ßek
                frames = realsense_pipeline.wait_for_frames()
                color_frame = frames.get_color_frame()
                
                if color_frame:
                    frame = np.asanyarray(color_frame.get_data())
                    frame = cv2.flip(frame, 1)  # Aynala
                    
                    # Fotoƒüraf √ßekildi, analiz et
                    socketio.emit('food_analysis_started')
                    
                    # Ger√ßek yemek analizi
                    analysis_result = analyze_food_with_clarifai(frame)
                    
                    # Sonucu g√∂nder
                    _, buffer = cv2.imencode('.jpg', frame)
                    img_base64 = base64.b64encode(buffer).decode('utf-8')
                    
                    socketio.emit('food_analysis_result', {
                        'image': img_base64,
                        'analysis': analysis_result
                    })
                    
                    print(f"‚úÖ RealSense yemek analizi tamamlandƒ±")
                else:
                    socketio.emit('food_analysis_error', {'message': 'RealSense fotoƒüraf √ßekilemedi'})
                
                realsense_pipeline.stop()
                
            except Exception as e:
                print(f"‚ùå RealSense yemek fotoƒürafƒ± hatasƒ±: {e}")
                socketio.emit('food_analysis_error', {'message': f'RealSense hatasƒ±: {str(e)}'})
        
        else:
            # Webcam ile fotoƒüraf √ßek
            try:
                working_cameras = [4, 6, 2, 0, 1]
                working_camera_index = None
                
                for camera_index in working_cameras:
                    test_cap = cv2.VideoCapture(camera_index)
                    if test_cap.isOpened():
                        ret, frame = test_cap.read()
                        if ret and frame is not None:
                            working_camera_index = camera_index
                            test_cap.release()
                            break
                        test_cap.release()
                
                if working_camera_index is None:
                    socketio.emit('food_analysis_error', {'message': 'Webcam bulunamadƒ±'})
                    return
                
                camera = cv2.VideoCapture(working_camera_index)
                camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                
                # 3 saniye geri sayƒ±m
                for i in range(3, 0, -1):
                    socketio.emit('food_capture_countdown', {'count': i})
                    socketio.sleep(1)
                
                socketio.emit('food_capture_started')
                
                # Fotoƒüraf √ßek
                ret, frame = camera.read()
                if ret:
                    frame = cv2.flip(frame, 1)  # Aynala
                    
                    # Fotoƒüraf √ßekildi, analiz et
                    socketio.emit('food_analysis_started')
                    
                    # Ger√ßek yemek analizi
                    analysis_result = analyze_food_with_clarifai(frame)
                    
                    # Sonucu g√∂nder
                    _, buffer = cv2.imencode('.jpg', frame)
                    img_base64 = base64.b64encode(buffer).decode('utf-8')
                    
                    socketio.emit('food_analysis_result', {
                        'image': img_base64,
                        'analysis': analysis_result
                    })
                    
                    print(f"‚úÖ Webcam yemek analizi tamamlandƒ±")
                else:
                    socketio.emit('food_analysis_error', {'message': 'Webcam fotoƒüraf √ßekilemedi'})
                
                camera.release()
                
            except Exception as e:
                print(f"‚ùå Webcam yemek fotoƒürafƒ± hatasƒ±: {e}")
                socketio.emit('food_analysis_error', {'message': f'Webcam hatasƒ±: {str(e)}'})
    
    except Exception as e:
        print(f"‚ùå Genel yemek fotoƒürafƒ± hatasƒ±: {e}")
        socketio.emit('food_analysis_error', {'message': f'Genel hata: {str(e)}'})

def take_food_photo_realsense():
    """RealSense ile yemek fotoƒürafƒ± √ßek"""
    global realsense_pipeline
    
    try:
        realsense_pipeline = rs.pipeline()
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        
        profile = realsense_pipeline.start(config)
        
        print("‚úÖ RealSense fotoƒüraf √ßekimi ba≈ülatƒ±ldƒ±")
        
        # 3 saniye geri sayƒ±m
        for i in range(3, 0, -1):
            socketio.emit('food_capture_countdown', {'count': i})
            socketio.sleep(1)
        
        socketio.emit('food_capture_started')
        
        # Fotoƒüraf √ßek
        frames = realsense_pipeline.wait_for_frames(timeout_ms=5000)
        color_frame = frames.get_color_frame()
        
        if color_frame:
            color_image = np.asanyarray(color_frame.get_data())
            color_image = cv2.flip(color_image, 1)  # Aynala
            
            # JPEG olarak encode et
            _, buffer = cv2.imencode('.jpg', color_image, [cv2.IMWRITE_JPEG_QUALITY, 95])
            img_base64 = base64.b64encode(buffer).decode('utf-8')
            
            print("‚úÖ RealSense RGB fotoƒüraf √ßekildi")
            return img_base64
        else:
            print("‚ùå RealSense color frame alƒ±namadƒ±")
            return None
            
    except Exception as e:
        print(f"‚ùå RealSense fotoƒüraf √ßekme hatasƒ±: {e}")
        return None
    finally:
        if realsense_pipeline:
            try:
                realsense_pipeline.stop()
            except:
                pass

def process_food_photo():
    """Yemek fotoƒürafƒ±nƒ± i≈üle ve kalori hesapla"""
    global calorie_calculation_active
    
    try:
        calorie_calculation_active = True
        
        # 3-2-1 geri sayƒ±m
        for i in range(FOOD_CAPTURE_COUNTDOWN, 0, -1):
            safe_emit('food_capture_countdown', {'count': i})
            socketio.sleep(1)
        
        # Fotoƒüraf √ßekme ba≈üladƒ±
        safe_emit('food_capture_started')
        socketio.sleep(0.5)
        
        # Frame yakala
        captured_frame = capture_single_frame()
        
        if captured_frame is None:
            safe_emit('food_analysis_error', {'message': 'Fotoƒüraf √ßekilemedi'})
            return
        
        # RGB fotoƒürafƒ± base64'e √ßevir (JPEG formatƒ±nda)
        _, buffer = cv2.imencode('.jpg', captured_frame, [cv2.IMWRITE_JPEG_QUALITY, 90])
        img_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # Analiz ba≈üladƒ±
        safe_emit('food_analysis_started')
        socketio.sleep(1)  # Analiz sim√ºlasyonu
        
        # Yemek tespiti yap (≈üimdilik sim√ºlasyon)
        food_analysis = simulate_food_detection(img_base64)
        
        # Sonu√ßlarƒ± g√∂nder
        safe_emit('food_analysis_result', {
            'image': img_base64,
            'analysis': food_analysis
        })
        
        print(f"‚úÖ Kalori hesaplama tamamlandƒ±: {food_analysis['total_calories']} kcal")
        
    except Exception as e:
        print(f"‚ùå Yemek fotoƒürafƒ± i≈üleme hatasƒ±: {e}")
        safe_emit('food_analysis_error', {'message': f'ƒ∞≈üleme hatasƒ±: {str(e)}'})
    finally:
        calorie_calculation_active = False

# Model y√ºklemeyi dene
if not load_movenet_model():
    print("üõë Sistem model olmadan √ßalƒ±≈üamaz. √áƒ±kƒ±lƒ±yor...")
    exit(1)

INPUT_SIZE = 192

# --- Diyet √ñnerileri Veritabanƒ± ---
DIYET_ONERILERI = {
    'Ektomorf': {
        'ozellikler': [
            'ƒ∞nce yapƒ±lƒ± ve hƒ±zlƒ± metabolizma',
            'Kilo almakta zorlanƒ±r',
            'Kas yapmak i√ßin daha fazla kalori gerekir',
            'Doƒüal olarak d√º≈ü√ºk v√ºcut yaƒü oranƒ±',
            'Uzun ve ince kemik yapƒ±sƒ±'
        ],
        'beslenme_ilkeleri': [
            'Y√ºksek kalori alƒ±mƒ± (g√ºnde 2500-3000 kalori)',
            'Karbonhidrat aƒüƒ±rlƒ±klƒ± beslenme (%50-60)',
            'Protein alƒ±mƒ± (v√ºcut aƒüƒ±rlƒ±ƒüƒ±nƒ±n kg ba≈üƒ±na 1.5-2g)',
            'Saƒülƒ±klƒ± yaƒülar (%20-30)',
            'Sƒ±k √∂ƒü√ºn t√ºketimi (6-8 √∂ƒü√ºn/g√ºn)',
            'Antrenman √∂ncesi ve sonrasƒ± beslenmeye dikkat'
        ],
        'onerilen_besinler': [
            'Tam tahƒ±l ekmek ve makarna',
            'Pirin√ß, bulgur, quinoa',
            'Tavuk, balƒ±k, yumurta',
            'Fƒ±ndƒ±k, badem, ceviz',
            'Avokado, zeytinyaƒüƒ±',
            'Muz, hurma, kuru meyve',
            'S√ºt, yoƒüurt, peynir',
            'Protein tozu ve gainers',
            'Tatlƒ± patates, yulaf'
        ],
        'kacinilmasi_gerekenler': [
            'A≈üƒ±rƒ± i≈ülenmi≈ü gƒ±dalar',
            '≈ûekerli i√ßecekler',
            'Trans yaƒülar',
            'A≈üƒ±rƒ± kafein',
            'Bo≈ü kalori i√ßeren atƒ±≈ütƒ±rmalƒ±klar'
        ],
        'ogun_plani': {
            'pazartesi': {
                'kahvalti': 'Yulaf ezmesi + muz + fƒ±ndƒ±k + s√ºt + bal',
                'ara_ogun_1': 'Tam tahƒ±l kraker + peynir + ceviz',
                'ogle': 'Tavuk + pirin√ß + salata + zeytinyaƒüƒ± + avokado',
                'ara_ogun_2': 'Protein smoothie + meyve + yoƒüurt',
                'aksam': 'Balƒ±k + bulgur pilavƒ± + sebze + zeytinyaƒüƒ±',
                'gece': 'Yoƒüurt + bal + ceviz + hurma'
            },
            'sali': {
                'kahvalti': 'Omlet (3 yumurta) + tam tahƒ±l ekmek + domates + peynir',
                'ara_ogun_1': 'Muz + badem + s√ºt',
                'ogle': 'Dana eti + makarna + salata + parmesan',
                'ara_ogun_2': 'Protein bar + elma',
                'aksam': 'Somon + quinoa + buharda sebze',
                'gece': 'S√ºt + tar√ßƒ±n + bal + fƒ±ndƒ±k'
            },
            'carsamba': {
                'kahvalti': 'M√ºsli + yoƒüurt + meyve + fƒ±ndƒ±k',
                'ara_ogun_1': 'Tam tahƒ±l sandvi√ß + hindi + peynir',
                'ogle': 'K√∂fte + bulgur + cacƒ±k + salata',
                'ara_ogun_2': 'Smoothie (muz + protein + s√ºt)',
                'aksam': 'Tavuk + tatlƒ± patates + ye≈üil fasulye',
                'gece': 'Yoƒüurt + granola + bal'
            },
            'persembe': {
                'kahvalti': 'Pancake (yulaf unu) + meyve + ak√ßaaƒüa√ß ≈üurubu',
                'ara_ogun_1': 'Kuruyemi≈ü karƒ±≈üƒ±mƒ± + kuru meyve',
                'ogle': 'Balƒ±k + pirin√ß + sebze sote',
                'ara_ogun_2': 'Yoƒüurt + meyve + granola',
                'aksam': 'Tavuk + makarna + brokoli',
                'gece': 'S√ºt + bisk√ºvi + fƒ±ndƒ±k ezmesi'
            },
            'cuma': {
                'kahvalti': 'Menemen + peynir + tam tahƒ±l ekmek',
                'ara_ogun_1': 'Protein shake + muz',
                'ogle': 'Tavuk d√∂ner + bulgur + salata',
                'ara_ogun_2': 'Elma + fƒ±ndƒ±k ezmesi',
                'aksam': 'Balƒ±k + pirin√ß + karƒ±≈üƒ±k sebze',
                'gece': 'Yoƒüurt + bal + ceviz'
            },
            'cumartesi': {
                'kahvalti': 'French toast + meyve + s√ºt',
                'ara_ogun_1': 'Smoothie bowl + granola',
                'ogle': 'K√∂ri tavuk + pirin√ß + naan',
                'ara_ogun_2': 'Protein bar + kuruyemi≈ü',
                'aksam': 'Biftek + patates + salata',
                'gece': 'S√ºt + tar√ßƒ±n + bal'
            },
            'pazar': {
                'kahvalti': 'Kahvaltƒ± tabaƒüƒ± (yumurta + peynir + zeytin + ekmek)',
                'ara_ogun_1': 'Meyve salatasƒ± + yoƒüurt',
                'ogle': 'Kuzu eti + bulgur + sebze',
                'ara_ogun_2': 'Protein smoothie + hurma',
                'aksam': 'Balƒ±k + quinoa + asparagus',
                'gece': 'Yoƒüurt + granola + meyve'
            }
        }
    },
    'Mezomorf': {
        'ozellikler': [
            'Atletik yapƒ± ve orta metabolizma',
            'Kas yapma ve yaƒü yakma dengeli',
            'V√ºcut kompozisyonunu korumak kolay',
            'Doƒüal kas yapƒ±sƒ± iyi',
            'Orta kemik yapƒ±sƒ±'
        ],
        'beslenme_ilkeleri': [
            'Dengeli kalori alƒ±mƒ± (g√ºnde 2000-2500 kalori)',
            'Dengeli makro besin daƒüƒ±lƒ±mƒ±',
            'Protein alƒ±mƒ± (v√ºcut aƒüƒ±rlƒ±ƒüƒ±nƒ±n kg ba≈üƒ±na 1.2-1.5g)',
            'Karbonhidrat (%40-45), Yaƒü (%25-30)',
            'D√ºzenli √∂ƒü√ºn saatleri (5-6 √∂ƒü√ºn/g√ºn)',
            'Antrenman periyodizasyonuna uygun beslenme'
        ],
        'onerilen_besinler': [
            'Yaƒüsƒ±z et, tavuk, balƒ±k',
            'Yumurta ve s√ºt √ºr√ºnleri',
            'Tam tahƒ±l √ºr√ºnleri',
            'Taze meyve ve sebzeler',
            'Bakliyat (mercimek, nohut)',
            'Fƒ±ndƒ±k ve tohum',
            'Zeytinyaƒüƒ±, balƒ±k yaƒüƒ±',
            'Quinoa, bulgur',
            'Ye≈üil yapraklƒ± sebzeler'
        ],
        'kacinilmasi_gerekenler': [
            'A≈üƒ±rƒ± kalori alƒ±mƒ±',
            'Rafine ≈üeker',
            'ƒ∞≈ülenmi≈ü et √ºr√ºnleri',
            'A≈üƒ±rƒ± doymu≈ü yaƒü',
            'Alkol'
        ],
        'ogun_plani': {
            'pazartesi': {
                'kahvalti': 'Omlet + tam tahƒ±l ekmek + domates + zeytinyaƒüƒ±',
                'ara_ogun_1': 'Elma + badem + yoƒüurt',
                'ogle': 'Izgara tavuk + quinoa + ye≈üil salata + zeytinyaƒüƒ±',
                'ara_ogun_2': 'Yoƒüurt + meyve + ceviz',
                'aksam': 'Balƒ±k + tatlƒ± patates + buharda sebze',
                'gece': 'Az yaƒülƒ± s√ºt + tar√ßƒ±n + bal'
            },
            'sali': {
                'kahvalti': 'Yulaf ezmesi + meyve + fƒ±ndƒ±k + s√ºt',
                'ara_ogun_1': 'Tam tahƒ±l kraker + peynir',
                'ogle': 'Dana eti + bulgur + salata',
                'ara_ogun_2': 'Smoothie (meyve + yoƒüurt)',
                'aksam': 'Tavuk + pirin√ß + sebze sote',
                'gece': 'Yoƒüurt + bal + ceviz'
            },
            'carsamba': {
                'kahvalti': 'Peynirli omlet + tam tahƒ±l ekmek + salatalƒ±k',
                'ara_ogun_1': 'Muz + fƒ±ndƒ±k ezmesi',
                'ogle': 'Balƒ±k + quinoa + ye≈üil fasulye',
                'ara_ogun_2': 'Yoƒüurt + granola',
                'aksam': 'Tavuk + bulgur + karƒ±≈üƒ±k salata',
                'gece': 'S√ºt + tar√ßƒ±n'
            },
            'persembe': {
                'kahvalti': 'M√ºsli + yoƒüurt + meyve',
                'ara_ogun_1': 'Elma + badem',
                'ogle': 'K√∂fte + pirin√ß + cacƒ±k',
                'ara_ogun_2': 'Protein smoothie',
                'aksam': 'Somon + tatlƒ± patates + brokoli',
                'gece': 'Yoƒüurt + bal'
            },
            'cuma': {
                'kahvalti': 'Menemen + peynir + ekmek',
                'ara_ogun_1': 'Kuruyemi≈ü karƒ±≈üƒ±mƒ±',
                'ogle': 'Tavuk + makarna + salata',
                'ara_ogun_2': 'Yoƒüurt + meyve',
                'aksam': 'Balƒ±k + bulgur + sebze',
                'gece': 'S√ºt + bisk√ºvi'
            },
            'cumartesi': {
                'kahvalti': 'Pancake + meyve + bal',
                'ara_ogun_1': 'Smoothie bowl',
                'ogle': 'Izgara et + quinoa + salata',
                'ara_ogun_2': 'Yoƒüurt + granola',
                'aksam': 'Tavuk + pirin√ß + sebze',
                'gece': 'S√ºt + tar√ßƒ±n + bal'
            },
            'pazar': {
                'kahvalti': 'Kahvaltƒ± tabaƒüƒ± (dengeli)',
                'ara_ogun_1': 'Meyve + yoƒüurt',
                'ogle': 'Balƒ±k + bulgur + salata',
                'ara_ogun_2': 'Fƒ±ndƒ±k + kuru meyve',
                'aksam': 'Tavuk + quinoa + sebze',
                'gece': 'Yoƒüurt + bal + ceviz'
            }
        }
    },
    'Endomorf': {
        'ozellikler': [
            'Geni≈ü yapƒ±lƒ± ve yava≈ü metabolizma',
            'Kilo almaya eƒüilimli',
            'Yaƒü yakmak i√ßin daha fazla √ßaba gerekir',
            'Doƒüal olarak y√ºksek v√ºcut yaƒü oranƒ±',
            'Geni≈ü kemik yapƒ±sƒ±'
        ],
        'beslenme_ilkeleri': [
            'Kontroll√º kalori alƒ±mƒ± (g√ºnde 1500-2000 kalori)',
            'D√º≈ü√ºk karbonhidrat (%30-35)',
            'Y√ºksek protein (v√ºcut aƒüƒ±rlƒ±ƒüƒ±nƒ±n kg ba≈üƒ±na 1.5-2g)',
            'Orta yaƒü alƒ±mƒ± (%25-30)',
            'Sƒ±k ve k√º√ß√ºk √∂ƒü√ºnler (6-7 √∂ƒü√ºn/g√ºn)',
            'Glisemik indeksi d√º≈ü√ºk besinler'
        ],
        'onerilen_besinler': [
            'Yaƒüsƒ±z protein (tavuk g√∂ƒüs√º, balƒ±k)',
            'Ye≈üil yapraklƒ± sebzeler',
            'D√º≈ü√ºk glisemik indeksli meyveler',
            'Tam tahƒ±l √ºr√ºnleri (az miktarda)',
            'Bakliyat ve mercimek',
            'Fƒ±ndƒ±k (kontroll√º miktarda)',
            'Zeytinyaƒüƒ±, avokado',
            'Brokoli, karnabahar',
            'Yaban mersini, √ßilek'
        ],
        'kacinilmasi_gerekenler': [
            'Basit karbonhidratlar',
            '≈ûekerli gƒ±dalar ve i√ßecekler',
            'ƒ∞≈ülenmi≈ü gƒ±dalar',
            'Y√ºksek kalorili atƒ±≈ütƒ±rmalƒ±klar',
            'Beyaz ekmek, pasta',
            'Alkol',
            'Ge√ß saatlerde yemek'
        ],
        'ogun_plani': {
            'pazartesi': {
                'kahvalti': 'Protein omlet + sebze + az zeytinyaƒüƒ± + ye≈üil √ßay',
                'ara_ogun_1': '√áiƒü badem (10-15 adet) + ye≈üil elma',
                'ogle': 'Izgara balƒ±k + bol salata + limon + zeytinyaƒüƒ±',
                'ara_ogun_2': 'Yoƒüurt (≈üekersiz) + tar√ßƒ±n + ceviz',
                'aksam': 'Tavuk + buharda brokoli + bulgur (az)',
                'gece': 'Bitki √ßayƒ± + badem (5-6 adet)'
            },
            'sali': {
                'kahvalti': 'Sebzeli omlet + domates + salatalƒ±k',
                'ara_ogun_1': 'Yoƒüurt (≈üekersiz) + √ßilek',
                'ogle': 'Tavuk salatasƒ± + ye≈üil yapraklar + zeytinyaƒüƒ±',
                'ara_ogun_2': 'Fƒ±ndƒ±k (10 adet) + ye≈üil √ßay',
                'aksam': 'Balƒ±k + karnabahar + az bulgur',
                'gece': 'Bitki √ßayƒ±'
            },
            'carsamba': {
                'kahvalti': 'Protein shake + sebze + avokado',
                'ara_ogun_1': 'Elma + badem ezmesi (az)',
                'ogle': 'Dana eti + bol salata + limon',
                'ara_ogun_2': 'Yoƒüurt + yaban mersini',
                'aksam': 'Tavuk + buharda sebze + quinoa (az)',
                'gece': 'Ye≈üil √ßay + ceviz (3-4 adet)'
            },
            'persembe': {
                'kahvalti': 'Omlet + ƒ±spanak + mantar',
                'ara_ogun_1': 'Yoƒüurt + tar√ßƒ±n',
                'ogle': 'Balƒ±k + ye≈üil salata + avokado',
                'ara_ogun_2': 'Badem (8-10 adet) + √ßay',
                'aksam': 'Tavuk + brokoli + tatlƒ± patates (az)',
                'gece': 'Bitki √ßayƒ±'
            },
            'cuma': {
                'kahvalti': 'Protein omlet + sebze karƒ±≈üƒ±mƒ±',
                'ara_ogun_1': '√áilek + yoƒüurt (≈üekersiz)',
                'ogle': 'Izgara tavuk + bol ye≈üillik + zeytinyaƒüƒ±',
                'ara_ogun_2': 'Fƒ±ndƒ±k + ye≈üil √ßay',
                'aksam': 'Balƒ±k + asparagus + bulgur (az)',
                'gece': 'Bitki √ßayƒ± + badem (5 adet)'
            },
            'cumartesi': {
                'kahvalti': 'Sebzeli scrambled egg + domates',
                'ara_ogun_1': 'Yoƒüurt + yaban mersini',
                'ogle': 'Balƒ±k salatasƒ± + ye≈üil yapraklar',
                'ara_ogun_2': 'Elma + badem (8 adet)',
                'aksam': 'Tavuk + karƒ±≈üƒ±k sebze + quinoa (az)',
                'gece': 'Ye≈üil √ßay'
            },
            'pazar': {
                'kahvalti': 'Protein omlet + avokado + domates',
                'ara_ogun_1': 'Yoƒüurt + tar√ßƒ±n + ceviz (3 adet)',
                'ogle': 'Izgara et + b√ºy√ºk salata + limon',
                'ara_ogun_2': '√áilek + badem (6 adet)',
                'aksam': 'Balƒ±k + buharda sebze + bulgur (az)',
                'gece': 'Bitki √ßayƒ±'
            }
        }
    }
}

# --- Body Parts and Skeleton Definitions ---
KEYPOINT_DICT = {
    'nose': 0, 'left_eye': 1, 'right_eye': 2, 'left_ear': 3, 'right_ear': 4,
    'left_shoulder': 5, 'right_shoulder': 6, 'left_elbow': 7, 'right_elbow': 8,
    'left_wrist': 9, 'right_wrist': 10, 'left_hip': 11, 'right_hip': 12,
    'left_knee': 13, 'right_knee': 14, 'left_ankle': 15, 'right_ankle': 16
}

EDGES = [
    (5, 6), (5, 7), (7, 9), (6, 8), (8, 10), (5, 11), 
    (6, 12), (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)
]

def run_movenet(input_image: np.ndarray) -> np.ndarray:
    """Run MoveNet model on input image and return keypoints"""
    if movenet is None:
        return np.zeros((17, 3))
        
    img_resized = tf.image.resize_with_pad(np.expand_dims(input_image, axis=0), INPUT_SIZE, INPUT_SIZE)
    input_tensor = tf.cast(img_resized, dtype=tf.int32)
    
    try:
        outputs = movenet(input_tensor)
        return outputs['output_0'].numpy()[0, 0]
    except Exception as e:
        print(f"‚ùå Model √ßalƒ±≈ütƒ±rma hatasƒ±: {e}")
        return np.zeros((17, 3))

def calculate_pixel_distance(p1: Tuple[int, int], p2: Tuple[int, int]) -> float:
    """Calculate pixel distance between two points"""
    return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)

def safe_array_access(depth_array: np.ndarray, y: int, x: int) -> float:
    """Safely access depth array with bounds checking"""
    try:
        height, width = depth_array.shape[:2]
        y = max(0, min(height - 1, y))
        x = max(0, min(width - 1, x))
        return float(depth_array[y, x])
    except Exception as e:
        return 0.0

def calculate_3d_distance_safe(p1: Tuple[int, int], p2: Tuple[int, int], 
                              depth_frame, depth_intrinsics) -> Optional[float]:
    """Safely calculate 3D distance between two points using depth data"""
    try:
        depth_image = np.asanyarray(depth_frame.get_data())
        depth_units = depth_frame.get_units()
        
        # Daha geni≈ü alan ortalamasƒ± al (5x5 piksel)
        depth1_values = []
        depth2_values = []
        
        for dy in range(-2, 3):
            for dx in range(-2, 3):
                d1 = safe_array_access(depth_image, p1[1] + dy, p1[0] + dx) * depth_units
                d2 = safe_array_access(depth_image, p2[1] + dy, p2[0] + dx) * depth_units
                if d1 > 0: depth1_values.append(d1)
                if d2 > 0: depth2_values.append(d2)
        
        if not depth1_values or not depth2_values:
            return None
            
        depth1 = np.median(depth1_values)  # Median daha kararlƒ±
        depth2 = np.median(depth2_values)
        
        if depth1 <= 0.3 or depth2 <= 0.3 or depth1 > 3.0 or depth2 > 3.0:
            return None
            
        # Derinlik farkƒ± √ßok fazlaysa g√ºvenilmez
        if abs(depth1 - depth2) > 0.5:
            return None
            
        point1_3d = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [p1[0], p1[1]], depth1)
        point2_3d = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [p2[0], p2[1]], depth2)
        
        distance = np.linalg.norm(np.subtract(point1_3d, point2_3d))
        distance_cm = distance * 100
        
        # Daha ger√ßek√ßi sƒ±nƒ±rlar
        if distance_cm < 15 or distance_cm > 80:
            return None
            
        return distance_cm
        
    except Exception as e:
        return None

def analyze_body_measurements(keypoints: np.ndarray, frame_shape: Tuple[int, int], 
                            depth_frame=None, depth_intrinsics=None) -> Dict[str, Any]:
    """Comprehensive body measurement analysis"""
    global current_analysis
    
    height, width = frame_shape[:2]
    
    analysis_data = {
        'omuz_genisligi': 0.0,
        'bel_genisligi': 0.0,
        'omuz_bel_orani': 0.0,
        'vucut_tipi': 'Analiz Bekleniyor',
        'mesafe': 0.0,
        'confidence': 0.0
    }
    
    try:
        if len(keypoints) < 17:
            return analysis_data
            
        # Extract keypoints
        ls_y, ls_x, ls_c = keypoints[KEYPOINT_DICT['left_shoulder']]
        rs_y, rs_x, rs_c = keypoints[KEYPOINT_DICT['right_shoulder']]
        lh_y, lh_x, lh_c = keypoints[KEYPOINT_DICT['left_hip']]
        rh_y, rh_x, rh_c = keypoints[KEYPOINT_DICT['right_hip']]
        
        # Calculate shoulder width
        shoulder_width = 0.0
        if ls_c > 0.3 and rs_c > 0.3:
            p1 = (int(ls_x * width), int(ls_y * height))
            p2 = (int(rs_x * width), int(rs_y * height))
            
            if depth_frame is not None and depth_intrinsics is not None:
                # RealSense 3D measurement
                shoulder_width = calculate_3d_distance_safe(p1, p2, depth_frame, depth_intrinsics)
                
                # 3D ba≈üarƒ±sƒ±z olursa 2D'ye ge√ß
                if shoulder_width is None:
                    pixel_distance = calculate_pixel_distance(p1, p2)
                    if analysis_data.get('mesafe', 0) > 0:
                        distance_factor = analysis_data['mesafe']
                        shoulder_width = (pixel_distance / width) * (45 * distance_factor)
                    else:
                        shoulder_width = (pixel_distance / width) * 90
                    shoulder_width = max(25, min(75, shoulder_width))
            else:
                # Webcam pixel-based measurement
                pixel_distance = calculate_pixel_distance(p1, p2)
                shoulder_width = (pixel_distance / width) * 90
                shoulder_width = max(25, min(75, shoulder_width))
            
            if shoulder_width:
                analysis_data['omuz_genisligi'] = shoulder_width
        
        # Calculate waist width
        waist_width = 0.0
        if lh_c > 0.3 and rh_c > 0.3:
            p1 = (int(lh_x * width), int(lh_y * height))
            p2 = (int(rh_x * width), int(rh_y * height))
            
            if depth_frame is not None and depth_intrinsics is not None:
                # RealSense 3D measurement
                waist_width = calculate_3d_distance_safe(p1, p2, depth_frame, depth_intrinsics)
                
                # 3D ba≈üarƒ±sƒ±z olursa 2D'ye ge√ß
                if waist_width is None:
                    pixel_distance = calculate_pixel_distance(p1, p2)
                    if analysis_data.get('mesafe', 0) > 0:
                        distance_factor = analysis_data['mesafe']
                        waist_width = (pixel_distance / width) * (35 * distance_factor)
                    else:
                        waist_width = (pixel_distance / width) * 70
                    waist_width = max(20, min(55, waist_width))
            else:
                # Webcam pixel-based measurement
                pixel_distance = calculate_pixel_distance(p1, p2)
                waist_width = (pixel_distance / width) * 70
                waist_width = max(20, min(55, waist_width))
            
            if waist_width:
                analysis_data['bel_genisligi'] = waist_width
        
        # Calculate ratios and body type
        if analysis_data['omuz_genisligi'] > 0 and analysis_data['bel_genisligi'] > 0:
            ratio = analysis_data['omuz_genisligi'] / analysis_data['bel_genisligi']
            analysis_data['omuz_bel_orani'] = ratio
            
            # Body type classification
            if ratio > 1.4:
                analysis_data['vucut_tipi'] = "Ektomorf"
            elif ratio > 1.2:
                analysis_data['vucut_tipi'] = "Mezomorf"
            else:
                analysis_data['vucut_tipi'] = "Endomorf"
            
            # Confidence calculation
            confidence = (ls_c + rs_c + lh_c + rh_c) / 4
            analysis_data['confidence'] = min(1.0, confidence)
        
        # Calculate distance to person
        if depth_frame is not None:
            if ls_c > 0.3 and rs_c > 0.3:
                center_x = int((ls_x + rs_x) * width / 2)
                center_y = int((ls_y + rs_y) * height / 2)
                
                try:
                    depth_image = np.asanyarray(depth_frame.get_data())
                    distance = safe_array_access(depth_image, center_y, center_x) * depth_frame.get_units()
                    if distance > 0:
                        analysis_data['mesafe'] = distance
                except Exception as e:
                    pass
        else:
            # Fixed distance for webcam
            analysis_data['mesafe'] = 1.5
        
        # Update current analysis
        current_analysis = analysis_data
        
    except Exception as e:
        print(f"‚ùå Analiz hatasƒ±: {e}")
    
    return analysis_data

def calculate_final_analysis():
    """Calculate final analysis from collected data"""
    global analysis_results, final_analysis
    
    if not analysis_results:
        return
    
    # Valid sonu√ßlarƒ± filtrele
    valid_results = [r for r in analysis_results if r['confidence'] > 0.5 and r['omuz_genisligi'] > 0 and r['bel_genisligi'] > 0]
    
    if not valid_results:
        print("‚ùå Yeterli ge√ßerli veri bulunamadƒ±")
        return
    
    # Ortalama deƒüerleri hesapla
    avg_shoulder = sum(r['omuz_genisligi'] for r in valid_results) / len(valid_results)
    avg_waist = sum(r['bel_genisligi'] for r in valid_results) / len(valid_results)
    avg_distance = sum(r['mesafe'] for r in valid_results) / len(valid_results)
    avg_confidence = sum(r['confidence'] for r in valid_results) / len(valid_results)
    
    # Final ratio ve body type
    final_ratio = avg_shoulder / avg_waist if avg_waist > 0 else 0
    
    if final_ratio > 1.4:
        body_type = "Ektomorf"
    elif final_ratio > 1.2:
        body_type = "Mezomorf"
    else:
        body_type = "Endomorf"
    
    # Final analizi g√ºncelle
    final_analysis.update({
        'omuz_genisligi': round(avg_shoulder, 1),
        'bel_genisligi': round(avg_waist, 1),
        'omuz_bel_orani': round(final_ratio, 2),
        'vucut_tipi': body_type,
        'mesafe': round(avg_distance, 1),
        'confidence': round(avg_confidence, 2),
        'diyet_onerileri': DIYET_ONERILERI.get(body_type, {})
    })
    
    print(f"‚úÖ Final Analiz: {body_type} - Omuz: {avg_shoulder:.1f}cm, Bel: {avg_waist:.1f}cm, Oran: {final_ratio:.2f}")

def draw_pose_and_measurements(frame: np.ndarray, keypoints: np.ndarray, 
                             analysis_data: Dict[str, Any], test_time_left: int) -> np.ndarray:
    """Draw pose skeleton and measurements on frame"""
    height, width, _ = frame.shape
    
    try:
        # Draw skeleton
        for p1_idx, p2_idx in EDGES:
            if p1_idx < len(keypoints) and p2_idx < len(keypoints):
                y1, x1, c1 = keypoints[p1_idx]
                y2, x2, c2 = keypoints[p2_idx]
                if c1 > 0.3 and c2 > 0.3:
                    pt1 = (int(x1 * width), int(y1 * height))
                    pt2 = (int(x2 * width), int(y2 * height))
                    cv2.line(frame, pt1, pt2, (0, 255, 0), 2)
        
        # Draw keypoints
        for i, (y, x, c) in enumerate(keypoints):
            if c > 0.3:
                pt = (int(x * width), int(y * height))
                cv2.circle(frame, pt, 4, (255, 0, 0), -1)
        
        # Extract keypoints for measurement lines
        ls_y, ls_x, ls_c = keypoints[KEYPOINT_DICT['left_shoulder']]
        rs_y, rs_x, rs_c = keypoints[KEYPOINT_DICT['right_shoulder']]
        lh_y, lh_x, lh_c = keypoints[KEYPOINT_DICT['left_hip']]
        rh_y, rh_x, rh_c = keypoints[KEYPOINT_DICT['right_hip']]
        
        # Shoulder measurement line
        if ls_c > 0.3 and rs_c > 0.3:
            pt1 = (int(ls_x * width), int(ls_y * height))
            pt2 = (int(rs_x * width), int(rs_y * height))
            cv2.line(frame, pt1, pt2, (255, 0, 255), 4)  # Kalƒ±n mor √ßizgi
            
            if analysis_data.get('omuz_genisligi', 0) > 0:
                mid_x = int((pt1[0] + pt2[0]) / 2)
                mid_y = int((pt1[1] + pt2[1]) / 2) - 15
                cv2.putText(frame, f"{analysis_data['omuz_genisligi']:.1f}cm", 
                           (mid_x - 40, mid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)
        
        # Hip measurement line
        if lh_c > 0.3 and rh_c > 0.3:
            pt1 = (int(lh_x * width), int(lh_y * height))
            pt2 = (int(rh_x * width), int(rh_y * height))
            cv2.line(frame, pt1, pt2, (255, 255, 0), 4)  # Kalƒ±n cyan √ßizgi
            
            if analysis_data.get('bel_genisligi', 0) > 0:
                mid_x = int((pt1[0] + pt2[0]) / 2)
                mid_y = int((pt1[1] + pt2[1]) / 2) + 25
                cv2.putText(frame, f"{analysis_data['bel_genisligi']:.1f}cm", 
                           (mid_x - 40, mid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # Add measurement text overlay
        y_offset = 30
        cv2.putText(frame, f"Omuz: {analysis_data.get('omuz_genisligi', 0):.1f}cm", 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        y_offset += 35
        cv2.putText(frame, f"Bel: {analysis_data.get('bel_genisligi', 0):.1f}cm", 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        y_offset += 35
        cv2.putText(frame, f"Tip: {analysis_data.get('vucut_tipi', 'Analiz Bekleniyor')}", 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        if analysis_data.get('omuz_bel_orani', 0) > 0:
            y_offset += 35
            cv2.putText(frame, f"Oran: {analysis_data['omuz_bel_orani']:.2f}", 
                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        if analysis_data.get('mesafe', 0) > 0:
            y_offset += 35
            cv2.putText(frame, f"Mesafe: {analysis_data['mesafe']:.1f}m", 
                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        # Test countdown
        cv2.putText(frame, f"Test Suresi: {test_time_left}s", 
                   (10, height - 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
        
        # Analysis count
        cv2.putText(frame, f"Analiz Sayisi: {len(analysis_results)}", 
                   (10, height - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
    except Exception as e:
        print(f"‚ùå √áizim hatasƒ±: {e}")
    
    return frame

def create_depth_visualization(frame: np.ndarray, keypoints: np.ndarray, 
                             depth_frame=None) -> np.ndarray:
    """Create depth visualization - real or simulated"""
    try:
        if depth_frame is not None:
            # Real depth from RealSense
            colorizer = rs.colorizer()
            colorizer.set_option(rs.option.color_scheme, 0)  # Jet colormap
            depth_colormap = np.asanyarray(colorizer.colorize(depth_frame).get_data())
            depth_colormap = cv2.flip(depth_colormap, 1)  # Mirror
        else:
            # Simulated depth from RGB
            height, width, _ = frame.shape
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            edges_inv = 255 - edges
            blurred = cv2.GaussianBlur(edges_inv, (21, 21), 0)
            blurred = cv2.equalizeHist(blurred)
            depth_colormap = cv2.applyColorMap(blurred, cv2.COLORMAP_JET)
        
        # Add pose skeleton to depth
        height, width = depth_colormap.shape[:2]
        for p1_idx, p2_idx in EDGES:
            if p1_idx < len(keypoints) and p2_idx < len(keypoints):
                y1, x1, c1 = keypoints[p1_idx]
                y2, x2, c2 = keypoints[p2_idx]
                if c1 > 0.3 and c2 > 0.3:
                    pt1 = (int(x1 * width), int(y1 * height))
                    pt2 = (int(x2 * width), int(y2 * height))
                    cv2.line(depth_colormap, pt1, pt2, (255, 255, 255), 2)
        
        # Add keypoints
        for i, (y, x, c) in enumerate(keypoints):
            if c > 0.3:
                pt = (int(x * width), int(y * height))
                cv2.circle(depth_colormap, pt, 3, (255, 255, 255), -1)
        
        return depth_colormap
        
    except Exception as e:
        print(f"‚ùå Derinlik g√∂rselle≈ütirme hatasƒ±: {e}")
        return np.zeros_like(frame)

def detect_camera_type():
    """Detect available camera type and return appropriate mode"""
    global camera_mode
    
    if REALSENSE_AVAILABLE:
        try:
            ctx = rs.context()
            devices = ctx.query_devices()
            if len(devices) > 0:
                print(f"‚úÖ {len(devices)} RealSense kamera bulundu")
                camera_mode = "realsense"
                return True
        except Exception as e:
            print(f"RealSense test failed: {e}")
    
    print("üìπ Normal webcam modu kullanƒ±lacak")
    camera_mode = "webcam"
    return True

def safe_emit(event, data=None):
    """Safely emit WebSocket message with error handling"""
    try:
        if len(connected_clients) > 0:
            if data is not None:
                socketio.emit(event, data)
            else:
                socketio.emit(event)
    except Exception as e:
        print(f"‚ùå Emit hatasƒ± ({event}): {e}")

def run_body_analysis_test():
    """Run 10-second body analysis test"""
    global test_running, camera, realsense_pipeline, camera_mode, analysis_results, final_analysis
    
    try:
        # Reset analysis data
        analysis_results = []
        final_analysis = {
            'omuz_genisligi': 0.0,
            'bel_genisligi': 0.0,
            'omuz_bel_orani': 0.0,
            'vucut_tipi': 'Analiz Bekleniyor',
            'mesafe': 0.0,
            'confidence': 0.0,
            'diyet_onerileri': []
        }
        
        # Detect camera type
        if not detect_camera_type():
            safe_emit('test_error', 'Hi√ßbir kamera bulunamadƒ±')
            return
        
        if camera_mode == "realsense":
            run_realsense_test()
        else:
            run_webcam_test()
            
    except Exception as e:
        print(f"‚ùå Test error: {e}")
        safe_emit('test_error', f'Test error: {str(e)}')
    finally:
        test_running = False

def run_realsense_test():
    """Run test with RealSense camera - improved timeout handling"""
    global test_running, realsense_pipeline, analysis_results
    
    try:
        realsense_pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        
        profile = realsense_pipeline.start(config)
        
        # Depth sensor ayarlarƒ± - hata yakalama ile
        depth_sensor = profile.get_device().first_depth_sensor()
        try:
            # Sadece mevcut olan ayarlarƒ± kullan
            if hasattr(rs.option, 'laser_power'):
                depth_sensor.set_option(rs.option.laser_power, 300)
            if hasattr(rs.option, 'confidence_threshold'):
                depth_sensor.set_option(rs.option.confidence_threshold, 1)
            print("‚úÖ RealSense depth sensor ayarlarƒ± uygulandƒ±")
        except Exception as e:
            print(f"‚ö†Ô∏è Depth sensor ayarlarƒ± uygulanamadƒ±: {e}")
        
        depth_intrinsics = profile.get_stream(rs.stream.depth).as_video_stream_profile().get_intrinsics()
        
        print("‚úÖ RealSense test ba≈ülatƒ±ldƒ±")
        safe_emit('test_started', {'duration': TEST_DURATION})
        
        start_time = time.time()
        last_analysis_time = 0
        frame_timeout_count = 0
        max_timeout_count = 10
        
        while test_running and (time.time() - start_time) < TEST_DURATION:
            try:
                # Daha kƒ±sa timeout ile frame bekle
                frames = realsense_pipeline.wait_for_frames(timeout_ms=1000)
                frame_timeout_count = 0  # Reset timeout counter
                
                align = rs.align(rs.stream.color)
                aligned_frames = align.process(frames)
                
                color_frame = aligned_frames.get_color_frame()
                depth_frame = aligned_frames.get_depth_frame()
                
                if not color_frame or not depth_frame:
                    continue
                
                # Depth filtering - hata yakalama ile
                try:
                    depth_frame = rs.decimation_filter(2).process(depth_frame)
                    depth_frame = rs.spatial_filter().process(depth_frame)
                    depth_frame = rs.temporal_filter().process(depth_frame)
                    depth_frame = rs.hole_filling_filter().process(depth_frame)
                except Exception as filter_error:
                    # Filtreleme ba≈üarƒ±sƒ±z olursa ham depth kullan
                    pass
                
                color_image = np.asanyarray(color_frame.get_data())
                color_image = cv2.flip(color_image, 1)
                
                # Parlaklƒ±k ve kontrast filtreleri uygula
                color_image = cv2.convertScaleAbs(color_image, alpha=1.8, beta=70)
                
                # Histogram e≈üitleme (parlaklƒ±ƒüƒ± dengeler)
                lab = cv2.cvtColor(color_image, cv2.COLOR_BGR2LAB)
                l, a, b = cv2.split(lab)
                l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(l)
                color_image = cv2.merge([l, a, b])
                color_image = cv2.cvtColor(color_image, cv2.COLOR_LAB2BGR)
                
                # Run pose detection
                keypoints = run_movenet(color_image)
                
                # Analyze measurements
                current_time = time.time()
                if current_time - last_analysis_time >= ANALYSIS_INTERVAL:
                    analysis_data = analyze_body_measurements(
                        keypoints, color_image.shape, depth_frame, depth_intrinsics
                    )
                    
                    if analysis_data['confidence'] > 0.2:
                        analysis_results.append(analysis_data)
                        print(f"üìä Analiz #{len(analysis_results)}: {analysis_data['vucut_tipi']}")
                    
                    last_analysis_time = current_time
                
                # Calculate remaining time
                time_left = int(TEST_DURATION - (current_time - start_time))
                
                # Draw pose and measurements
                rgb_frame = draw_pose_and_measurements(color_image.copy(), keypoints, 
                                                     current_analysis, time_left)
                
                # Create depth visualization
                depth_viz = create_depth_visualization(color_image, keypoints, depth_frame)
                
                # Add labels
                cv2.putText(rgb_frame, "RGB + Pose", (10, rgb_frame.shape[0] - 80), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.putText(depth_viz, "Derinlik", (10, depth_viz.shape[0] - 80), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
                # Combine frames
                h1, w1 = rgb_frame.shape[:2]
                h2, w2 = depth_viz.shape[:2]
                if h1 != h2:
                    depth_viz = cv2.resize(depth_viz, (w1, h1))
                
                combined_frame = np.hstack((rgb_frame, depth_viz))
                
                # Send video frame
                try:
                    _, buffer = cv2.imencode('.jpg', combined_frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
                    img_base64 = base64.b64encode(buffer).decode('utf-8')
                    safe_emit('test_frame', {'frame': img_base64, 'time_left': time_left})
                except Exception as emit_error:
                    print(f"‚ö†Ô∏è Frame g√∂nderme hatasƒ±: {emit_error}")
                
                socketio.sleep(0.033)  # ~30 FPS
                
            except RuntimeError as timeout_error:
                frame_timeout_count += 1
                print(f"‚ö†Ô∏è RealSense frame timeout #{frame_timeout_count}")
                
                if frame_timeout_count >= max_timeout_count:
                    print("‚ùå √áok fazla timeout, test durduruluyor")
                    break
                    
                socketio.sleep(0.1)
                continue
                
            except Exception as e:
                print(f"‚ùå RealSense loop error: {e}")
                socketio.sleep(0.1)
                continue
        
        # Test completed
        calculate_final_analysis()
        safe_emit('test_completed', final_analysis)
        print(f"‚úÖ Test tamamlandƒ±: {len(analysis_results)} analiz yapƒ±ldƒ±")
        
    except Exception as e:
        print(f"‚ùå RealSense test error: {e}")
        safe_emit('test_error', f'RealSense error: {str(e)}')
    
    finally:
        if realsense_pipeline:
            try:
                realsense_pipeline.stop()
            except:
                pass
        print("üõë RealSense test stopped")

def run_webcam_test():
    """Run test with webcam - improved timeout handling"""
    global test_running, camera, analysis_results
    
    try:
        working_cameras = [4, 6, 2, 0, 1]
        working_camera_index = None
        
        for camera_index in working_cameras:
            test_cap = cv2.VideoCapture(camera_index)
            if test_cap.isOpened():
                ret, frame = test_cap.read()
                if ret and frame is not None:
                    working_camera_index = camera_index
                    test_cap.release()
                    print(f"‚úÖ Webcam {camera_index} kullanƒ±lƒ±yor")
                    break
                test_cap.release()
        
        if working_camera_index is None:
            safe_emit('test_error', 'Webcam bulunamadƒ±')
            return
        
        camera = cv2.VideoCapture(working_camera_index)
        camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        camera.set(cv2.CAP_PROP_FPS, 30)
        
        # G√∂r√ºnt√º kalitesi ayarlarƒ±
        print("üîß Kamera ayarlarƒ± yapƒ±landƒ±rƒ±lƒ±yor...")
        camera.set(cv2.CAP_PROP_BRIGHTNESS, 128)  # Parlaklƒ±k (0-255)
        camera.set(cv2.CAP_PROP_CONTRAST, 60)     # Kontrast (0-100)
        camera.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25)  # Otomatik pozlamayƒ± kapat
        camera.set(cv2.CAP_PROP_EXPOSURE, -4)     # Manuel pozlama (-13 ile 0 arasƒ±)
        
        # Ayarlarƒ± kontrol et
        brightness = camera.get(cv2.CAP_PROP_BRIGHTNESS)
        contrast = camera.get(cv2.CAP_PROP_CONTRAST)
        exposure = camera.get(cv2.CAP_PROP_EXPOSURE)
        print(f"üìä Kamera ayarlarƒ± - Parlaklƒ±k: {brightness}, Kontrast: {contrast}, Pozlama: {exposure}")
        print("‚úÖ Webcam test ba≈ülatƒ±ldƒ±")
        safe_emit('test_started', {'duration': TEST_DURATION})
        
        start_time = time.time()
        last_analysis_time = 0
        failed_frame_count = 0
        max_failed_frames = 30
        
        while test_running and (time.time() - start_time) < TEST_DURATION:
            try:
                ret, frame = camera.read()
                if not ret:
                    failed_frame_count += 1
                    if failed_frame_count >= max_failed_frames:
                        print("‚ùå √áok fazla ba≈üarƒ±sƒ±z frame, test durduruluyor")
                        break
                    continue
                
                failed_frame_count = 0
                frame = cv2.flip(frame, 1)
                
                # 4. kamera i√ßin g√º√ßl√º parlaklƒ±k filtreleri
                # 1. Kontrast ve parlaklƒ±k artƒ±rma (daha g√º√ßl√º)
                alpha = 1.5  # Kontrast √ßarpanƒ± (1.0 = normal, 1.5 = %50 artƒ±≈ü)
                beta = 50    # Parlaklƒ±k ekleme (0-100 arasƒ±, 50 = orta-y√ºksek)
                frame = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)
                
                # 2. Gamma d√ºzeltmesi (karanlƒ±k alanlarƒ± aydƒ±nlatƒ±r)
                gamma = 1.2  # 1.0'dan b√ºy√ºk deƒüerler aydƒ±nlatƒ±r
                inv_gamma = 1.0 / gamma
                table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
                frame = cv2.LUT(frame, table)
                
                # 3. CLAHE (Contrast Limited Adaptive Histogram Equalization)
                # LAB renk uzayƒ±nda parlaklƒ±k kanalƒ±nƒ± iyile≈ütir
                lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
                l, a, b = cv2.split(lab)
                
                # CLAHE uygula (daha g√º√ßl√º ayarlar)
                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
                l = clahe.apply(l)
                
                # Parlaklƒ±k kanalƒ±nƒ± biraz daha artƒ±r
                l = cv2.add(l, 20)  # +20 parlaklƒ±k ekle
                l = np.clip(l, 0, 255)  # 0-255 arasƒ±nda tut
                
                # LAB'ƒ± tekrar birle≈ütir ve BGR'ye √ßevir
                lab = cv2.merge([l, a, b])
                frame = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
                
                # 4. Son dokunu≈ü: Hafif bulanƒ±kla≈ütƒ±rma ve keskinle≈ütirme
                # G√ºr√ºlt√ºy√º azalt
                frame = cv2.bilateralFilter(frame, 9, 75, 75)
                
                # Parlaklƒ±k ve kontrast filtreleri uygula
                frame = cv2.convertScaleAbs(frame, alpha=1.3, beta=30)
                
                # CLAHE (Contrast Limited Adaptive Histogram Equalization) uygula
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
                l, a, b = cv2.split(lab)
                cl = clahe.apply(l)
                limg = cv2.merge((cl,a,b))
                frame = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
                
                # Parlaklƒ±k ve kontrast filtreleri
                frame = cv2.convertScaleAbs(frame, alpha=1.3, beta=30)
                
                # CLAHE histogram e≈üitleme (karanlƒ±k alanlarƒ± aydƒ±nlatƒ±r)
                lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
                l, a, b = cv2.split(lab)
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                l = clahe.apply(l)
                frame = cv2.merge([l, a, b])
                frame = cv2.cvtColor(frame, cv2.COLOR_LAB2BGR)
                
                # Parlaklƒ±k ve kontrast filtreleri uygula
                frame = cv2.convertScaleAbs(frame, alpha=1.3, beta=30)
                
                # Histogram e≈üitleme (parlaklƒ±ƒüƒ± dengeler)
                lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
                l, a, b = cv2.split(lab)
                l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(l)
                frame = cv2.merge([l, a, b])
                frame = cv2.cvtColor(frame, cv2.COLOR_LAB2BGR)
                
                # G√∂r√ºnt√º iyile≈ütirme filtreleri
                # 1. Parlaklƒ±k ve kontrast ayarƒ±
                frame = cv2.convertScaleAbs(frame, alpha=1.3, beta=30)  # alpha=kontrast, beta=parlaklƒ±k
                
                # 2. Histogram e≈üitleme (daha iyi aydƒ±nlatma)
                lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
                l, a, b = cv2.split(lab)
                l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(l)
                frame = cv2.merge([l, a, b])
                frame = cv2.cvtColor(frame, cv2.COLOR_LAB2BGR)
                
                # 3. Gamma d√ºzeltmesi (daha parlak g√∂r√ºnt√º)
                gamma = 1.2
                inv_gamma = 1.0 / gamma
                table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
                frame = cv2.LUT(frame, table)
                
                # Run pose detection
                keypoints = run_movenet(frame)
                
                # Analyze measurements
                current_time = time.time()
                if current_time - last_analysis_time >= ANALYSIS_INTERVAL:
                    analysis_data = analyze_body_measurements(keypoints, frame.shape)
                    
                    if analysis_data['confidence'] > 0.2:
                        analysis_results.append(analysis_data)
                        print(f"üìä Analiz #{len(analysis_results)}: {analysis_data['vucut_tipi']}")
                    
                    last_analysis_time = current_time
                
                # Calculate remaining time
                time_left = int(TEST_DURATION - (current_time - start_time))
                
                # Draw pose and measurements
                rgb_frame = draw_pose_and_measurements(frame.copy(), keypoints, 
                                                     current_analysis, time_left)
                
                # Create depth simulation
                depth_viz = create_depth_visualization(frame, keypoints, None)
                
                # Add labels
                cv2.putText(rgb_frame, "RGB + Pose", (10, rgb_frame.shape[0] - 80), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                cv2.putText(depth_viz, "Derinlik Sim.", (10, depth_viz.shape[0] - 80), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
                # Combine frames
                h1, w1 = rgb_frame.shape[:2]
                h2, w2 = depth_viz.shape[:2]
                if h1 != h2:
                    depth_viz = cv2.resize(depth_viz, (w1, h1))
                
                combined_frame = np.hstack((rgb_frame, depth_viz))
                
                # Send video frame
                try:
                    _, buffer = cv2.imencode('.jpg', combined_frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
                    img_base64 = base64.b64encode(buffer).decode('utf-8')
                    safe_emit('test_frame', {'frame': img_base64, 'time_left': time_left})
                except Exception as emit_error:
                    print(f"‚ö†Ô∏è Frame g√∂nderme hatasƒ±: {emit_error}")
                
                socketio.sleep(0.033)  # ~30 FPS
                
            except Exception as e:
                print(f"‚ùå Webcam loop error: {e}")
                socketio.sleep(0.1)
                continue
        
        # Test completed
        calculate_final_analysis()
        safe_emit('test_completed', final_analysis)
        print(f"‚úÖ Test tamamlandƒ±: {len(analysis_results)} analiz yapƒ±ldƒ±")
        
    except Exception as e:
        print(f"‚ùå Webcam test error: {e}")
        safe_emit('test_error', f'Webcam error: {str(e)}')
    
    finally:
        if camera:
            camera.release()
        print("üõë Webcam test stopped")

def take_food_photo():
    """Yemek fotoƒürafƒ± √ßek ve analiz et"""
    global camera, realsense_pipeline, camera_mode, food_capture_active
    
    food_capture_active = True
    
    try:
        if not food_analyzer:
            socketio.emit('food_analysis_error', {'message': 'Food analyzer ba≈ülatƒ±lamadƒ±'})
            return
        
        # Kamera tipini belirle
        if not detect_camera_type():
            socketio.emit('food_analysis_error', {'message': 'Kamera bulunamadƒ±'})
            return
        
        # Geri sayƒ±m
        for i in range(FOOD_PHOTO_COUNTDOWN, 0, -1):
            socketio.emit('food_capture_countdown', {'count': i})
            time.sleep(1)
        
        socketio.emit('food_capture_started')
        
        # Fotoƒüraf √ßek
        image_data = None
        
        if camera_mode == "realsense":
            image_data = capture_realsense_photo()
        else:
            image_data = capture_webcam_photo()
        
        if image_data:
            socketio.emit('food_analysis_started')
            
            # Yemek analizi yap
            analysis_result = food_analyzer.analyze_food_image(image_data)
            
            # Sonucu g√∂nder
            socketio.emit('food_analysis_result', {
                'image': analysis_result['image'],
                'analysis': analysis_result
            })
            
            print(f"‚úÖ Yemek analizi tamamlandƒ±: {analysis_result['total_calories']} kalori")
        else:
            socketio.emit('food_analysis_error', {'message': 'Fotoƒüraf √ßekilemedi'})
            
    except Exception as e:
        print(f"‚ùå Yemek fotoƒürafƒ± hatasƒ±: {e}")
        socketio.emit('food_analysis_error', {'message': f'Hata: {str(e)}'})
    finally:
        food_capture_active = False

def capture_realsense_photo():
    """RealSense ile fotoƒüraf √ßek"""
    temp_pipeline = None
    
    try:
        # RealSense pipeline ba≈ülat
        temp_pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        
        profile = temp_pipeline.start(config)
        
        # Birka√ß frame bekle (kamera stabilize olsun)
        for _ in range(10):
            temp_pipeline.wait_for_frames()
        
        # Fotoƒüraf √ßek
        frames = temp_pipeline.wait_for_frames()
        color_frame = frames.get_color_frame()
        
        if color_frame:
            color_image = np.asanyarray(color_frame.get_data())
            color_image = cv2.flip(color_image, 1)  # Mirror
            
            # JPEG formatƒ±na √ßevir
            _, buffer = cv2.imencode('.jpg', color_image, [cv2.IMWRITE_JPEG_QUALITY, 95])
            return buffer.tobytes()
        
        return None
        
    except Exception as e:
        print(f"RealSense fotoƒüraf hatasƒ±: {e}")
        return None
    finally:
        if temp_pipeline:
            temp_pipeline.stop()

def capture_webcam_photo():
    """Webcam ile fotoƒüraf √ßek"""
    temp_camera = None
    
    try:
        # Webcam a√ß
        working_cameras = [0, 1, 2, 4, 6]
        working_camera_index = None
        
        for camera_index in working_cameras:
            test_cap = cv2.VideoCapture(camera_index)
            if test_cap.isOpened():
                ret, frame = test_cap.read()
                if ret and frame is not None:
                    working_camera_index = camera_index
                    test_cap.release()
                    break
                test_cap.release()
        
        if working_camera_index is None:
            return None
        
        temp_camera = cv2.VideoCapture(working_camera_index)
        temp_camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        temp_camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        # Birka√ß frame bekle
        for _ in range(10):
            temp_camera.read()
        
        # Fotoƒüraf √ßek
        ret, frame = temp_camera.read()
        
        if ret and frame is not None:
            frame = cv2.flip(frame, 1)  # Mirror
            
            # JPEG formatƒ±na √ßevir
            _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
            return buffer.tobytes()
        
        return None
        
    except Exception as e:
        print(f"Webcam fotoƒüraf hatasƒ±: {e}")
        return None
    finally:
        if temp_camera:
            temp_camera.release()

def analyze_food_image(image_data):
    """Yemek g√∂r√ºnt√ºs√ºn√º analiz et ve kalori hesapla"""
    try:
        # Basit sim√ºlasyon - ger√ßek API entegrasyonu i√ßin bu kƒ±smƒ± deƒüi≈ütirin
        print("üçΩÔ∏è Yemek analizi yapƒ±lƒ±yor...")
        
        # Rastgele yemek se√ßimi (demo i√ßin)
        import random
        detected_foods = []
        total_calories = 0
        
        # 1-3 arasƒ± rastgele yemek tespit et
        num_foods = random.randint(1, 3)
        food_names = list(SIMPLE_FOOD_DATABASE.keys())
        
        for i in range(num_foods):
            food_name = random.choice(food_names)
            food_data = SIMPLE_FOOD_DATABASE[food_name]
            
            # Porsiyon miktarƒ±nda varyasyon
            portion_variation = random.uniform(0.7, 1.3)
            actual_portion = food_data['typical_portion'] * portion_variation
            
            # Kalori hesaplama
            calories = (food_data['calories_per_100g'] * actual_portion) / 100
            
            detected_foods.append({
                'name': food_name.title(),
                'portion_g': round(actual_portion),
                'calories': round(calories)
            })
            
            total_calories += calories
        
        # G√ºvenilirlik skoru
        confidence = random.uniform(0.7, 0.95)
        
        result = {
            'detected_foods': detected_foods,
            'total_calories': round(total_calories),
            'confidence': confidence,
            'analysis_method': 'Simulated Analysis'
        }
        
        print(f"‚úÖ Yemek analizi tamamlandƒ±: {total_calories:.0f} kalori")
        return result
        
    except Exception as e:
        print(f"‚ùå Yemek analizi hatasƒ±: {e}")
        return {
            'detected_foods': [],
            'total_calories': 0,
            'confidence': 0,
            'error': str(e)
        }

def capture_food_photo():
    """Yemek fotoƒürafƒ± √ßek ve analiz et"""
    global food_capture_active, camera, realsense_pipeline, camera_mode
    
    try:
        food_capture_active = True
        
        # 3 saniye geri sayƒ±m
        for i in range(3, 0, -1):
            if not food_capture_active:
                return
            socketio.emit('food_capture_countdown', {'count': i})
            socketio.sleep(1)
        
        socketio.emit('food_capture_started')
        
        # Kamera t√ºr√ºn√º tespit et
        if not detect_camera_type():
            socketio.emit('food_analysis_error', {'message': 'Kamera bulunamadƒ±'})
            return
        
        captured_frame = None
        
        if camera_mode == "realsense":
            # RealSense ile fotoƒüraf √ßek
            try:
                temp_pipeline = rs.pipeline()
                config = rs.config()
                config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
                
                temp_pipeline.start(config)
                
                # Birka√ß frame bekle (kamera stabilize olsun)
                for _ in range(10):
                    frames = temp_pipeline.wait_for_frames()
                
                # Son frame'i al
                frames = temp_pipeline.wait_for_frames()
                color_frame = frames.get_color_frame()
                
                if color_frame:
                    captured_frame = np.asanyarray(color_frame.get_data())
                    captured_frame = cv2.flip(captured_frame, 1)
                
                temp_pipeline.stop()
                
            except Exception as e:
                print(f"RealSense fotoƒüraf √ßekme hatasƒ±: {e}")
        
        else:
            # Webcam ile fotoƒüraf √ßek
            try:
                working_cameras = [4, 6, 2, 0, 1]
                working_camera_index = None
                
                for camera_index in working_cameras:
                    test_cap = cv2.VideoCapture(camera_index)
                    if test_cap.isOpened():
                        ret, frame = test_cap.read()
                        if ret and frame is not None:
                            working_camera_index = camera_index
                            test_cap.release()
                            break
                        test_cap.release()
                
                if working_camera_index is not None:
                    temp_camera = cv2.VideoCapture(working_camera_index)
                    temp_camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                    temp_camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                    
                    # Birka√ß frame bekle
                    for _ in range(10):
                        ret, frame = temp_camera.read()
                    
                    # Son frame'i al
                    ret, frame = temp_camera.read()
                    if ret:
                        captured_frame = cv2.flip(frame, 1)
                    
                    temp_camera.release()
                
            except Exception as e:
                print(f"Webcam fotoƒüraf √ßekme hatasƒ±: {e}")
        
        if captured_frame is None:
            socketio.emit('food_analysis_error', {'message': 'Fotoƒüraf √ßekilemedi'})
            return
        
        # Fotoƒürafƒ± base64'e √ßevir
        _, buffer = cv2.imencode('.jpg', captured_frame, [cv2.IMWRITE_JPEG_QUALITY, 90])
        img_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # Analiz ba≈ülat
        socketio.emit('food_analysis_started')
        
        # Yemek analizini yap
        analysis_result = analyze_food_image(captured_frame)
        
        # Sonucu g√∂nder
        socketio.emit('food_analysis_result', {
            'image': img_base64,
            'analysis': analysis_result
        })
        
        print(f"‚úÖ Yemek fotoƒürafƒ± analizi tamamlandƒ±")
        
    except Exception as e:
        print(f"‚ùå Yemek fotoƒürafƒ± √ßekme hatasƒ±: {e}")
        socketio.emit('food_analysis_error', {'message': f'Hata: {str(e)}'})
    
    finally:
        food_capture_active = False

def heartbeat_monitor():
    """Background heartbeat to keep connections alive"""
    global heartbeat_active
    heartbeat_active = True
    
    while heartbeat_active:
        try:
            if len(connected_clients) > 0:
                safe_emit('heartbeat', {'timestamp': time.time()})
            socketio.sleep(30)  # Her 30 saniyede bir heartbeat
        except Exception as e:
            print(f"‚ùå Heartbeat hatasƒ±: {e}")
            socketio.sleep(5)

# --- SocketIO Events ---
@socketio.on('connect')
def handle_connect(auth):
    global connected_clients
    
    client_id = request.sid
    connected_clients.add(client_id)
    print(f"‚úÖ WebSocket connection established! Client: {client_id}")
    
    # Start heartbeat if first client
    if len(connected_clients) == 1:
        socketio.start_background_task(target=heartbeat_monitor)
    
    # Send connection confirmation
    safe_emit('connection_ok', {'status': 'connected', 'timestamp': time.time()})

@socketio.on('disconnect')
def handle_disconnect():
    global test_running, connected_clients, heartbeat_active
    
    client_id = request.sid
    connected_clients.discard(client_id)
    
    # Stop test if no clients connected
    if len(connected_clients) == 0:
        test_running = False
        heartbeat_active = False
    
    print(f"‚ùå WebSocket connection closed! Client: {client_id}, Remaining: {len(connected_clients)}")

@socketio.on('start_test')
def handle_start_test(data):
    global test_running, test_thread
    try:
        if not test_running:
            test_running = True
            test_thread = socketio.start_background_task(target=run_body_analysis_test)
            safe_emit('stream_started', {'type': 'stream_started'})
            print("üöÄ V√ºcut analizi testi ba≈ülatƒ±ldƒ±")
        else:
            print("‚ö†Ô∏è Test zaten √ßalƒ±≈üƒ±yor")
    except Exception as e:
        print(f"‚ùå Test ba≈ülatma hatasƒ±: {e}")
        safe_emit('test_error', f'Test ba≈ülatma hatasƒ±: {str(e)}')

@socketio.on('stop_test')
def handle_stop_test(data):
    global test_running
    try:
        test_running = False
        safe_emit('test_stopped')
        print("üõë Test durduruldu")
    except Exception as e:
        print(f"‚ùå Test durdurma hatasƒ±: {e}")

@socketio.on('take_food_photo')
def handle_take_food_photo(data):
    """Yemek fotoƒürafƒ± √ßekme isteƒüi"""
    if not test_running:  # Test √ßalƒ±≈ümƒ±yorsa fotoƒüraf √ßekebilir
        socketio.start_background_task(target=take_food_photo)
        print("üì∏ Yemek fotoƒürafƒ± √ßekiliyor")

# Heartbeat sistemi
@socketio.on('ping')
def handle_ping(data):
    try:
        safe_emit('pong', {'timestamp': time.time()})
    except Exception as e:
        print(f"‚ùå Ping hatasƒ±: {e}")

@socketio.on('check_connection')
def handle_check_connection():
    """Connection check handler - parametre gerektirmez"""
    try:
        safe_emit('connection_ok', {'status': 'ok', 'timestamp': time.time()})
    except Exception as e:
        print(f"‚ùå Connection check hatasƒ±: {e}")

def initialize_food_analyzer():
    """Food analyzer'ƒ± ba≈ülat"""
    global food_analyzer
    try:
        api_key = "920c5f81c0264c2ca92a1d916e604a7694c560e9"
        food_analyzer = FoodAnalyzer(api_key)
        print("‚úÖ Food analyzer ba≈ülatƒ±ldƒ±")
        return True
    except Exception as e:
        print(f"‚ùå Food analyzer ba≈ülatƒ±lamadƒ±: {e}")
        return False

if __name__ == '__main__':
    # Food analyzer'ƒ± ba≈ülat
    initialize_food_analyzer()
    
    print("üöÄ Starting Test-Based Body Analysis System...")
    print("üìã Features:")
    print("   - 10 saniye test s√ºresi")
    print("   - Otomatik kamera algƒ±lama")
    print("   - V√ºcut tipi analizi")
    print("   - Sol ekranda √∂l√ß√ºm verileri")
    print("   - Yemek fotoƒürafƒ± ile kalori hesaplama")
    print("   - Yemek fotoƒürafƒ± analizi ve kalori hesaplama")
    print("   - Yemek fotoƒürafƒ± analizi ve kalori hesaplama")
    print("   - RGB g√∂r√ºnt√º al")
    print("   - Geli≈ümi≈ü omuz algƒ±lama")
    print("   - Kararlƒ± WebSocket baƒülantƒ±sƒ±")
    print("   - Tamamen d√ºzeltilmi≈ü timeout y√∂netimi")
    print("   - Optimize edilmi≈ü hata yakalama")
    print("   - Kalori hesaplama √∂zelliƒüi")
    print("   - Yemek fotoƒürafƒ± √ßekme")
    print()
    
    if REALSENSE_AVAILABLE:
        print("‚úÖ RealSense support: Available")
    else:
        print("‚ö†Ô∏è RealSense support: Not available (webcam only)")
    
    print()
    try:
        socketio.run(app, host='0.0.0.0', port=5000, debug=False, 
                    use_reloader=False, log_output=False, allow_unsafe_werkzeug=True)
    except KeyboardInterrupt:
        print("\nüõë Sistem kapatƒ±lƒ±yor...")
        test_running = False
        heartbeat_active = False
    except Exception as e:
        print(f"‚ùå Server hatasƒ±: {e}")